{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## **Load the Dataset**"
   ],
   "metadata": {
    "id": "NDg-W_pFjnfP"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Robust CSV loading (try local folder first, then repo root dataset)\n",
    "_df = None\n",
    "for candidate in [\n",
    "    Path('job_descriptions.csv'),\n",
    "    Path('./dataset/job_descriptions.csv'),\n",
    "    Path(__file__).resolve().parent / 'job_descriptions.csv' if '__file__' in globals() else None\n",
    "]:\n",
    "    if candidate and Path(candidate).exists():\n",
    "        _df = pd.read_csv(candidate)\n",
    "        break\n",
    "if _df is None:\n",
    "    # Fallback to original (may fail if path is wrong)\n",
    "    _df = pd.read_csv('job_descriptions.csv')\n",
    "\n",
    "df = _df\n",
    "print('Loaded rows:', len(df))\n",
    "df.head()\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 583
    },
    "id": "1Vi_dQd-jmcD",
    "outputId": "33643f55-48c7-47d8-8035-523310966127",
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Basic Exploration**"
   ],
   "metadata": {
    "id": "yZRZYda8lXDs"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print('Number of rows:', df.shape[0])\n",
    "print('Number of columns:', df.shape[1])\n",
    "\n",
    "print('Name of columns:', df.columns.tolist())\n",
    "print('Data types:', df.info())\n",
    "\n",
    "print('Summary:', df.describe(include='all'))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xq-0Udspli-s",
    "outputId": "dbb75c86-5d22-40db-8fb6-f0dc0ea24ca4",
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Check Missing Data**"
   ],
   "metadata": {
    "id": "_ISU6yJ2pTZk"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "df.isnull().sum()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 805
    },
    "id": "Ar9UUHZ8pY74",
    "outputId": "01c667be-03c2-4df4-e24b-33eab64ac706"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Job Id              0\n",
       "Experience          0\n",
       "Qualifications      0\n",
       "Salary Range        0\n",
       "location            0\n",
       "Country             0\n",
       "latitude            0\n",
       "longitude           0\n",
       "Work Type           0\n",
       "Company Size        0\n",
       "Job Posting Date    0\n",
       "Preference          0\n",
       "Contact Person      0\n",
       "Contact             0\n",
       "Job Title           0\n",
       "Role                0\n",
       "Job Portal          0\n",
       "Job Description     0\n",
       "Benefits            0\n",
       "skills              0\n",
       "Responsibilities    0\n",
       "Company             1\n",
       "Company Profile     3\n",
       "dtype: int64"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Job Id</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experience</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qualifications</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Salary Range</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latitude</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longitude</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Work Type</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Company Size</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job Posting Date</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Preference</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Contact Person</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Contact</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job Title</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Role</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job Portal</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job Description</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Benefits</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skills</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Responsibilities</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Company</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Company Profile</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><br><label><b>dtype:</b> int64</label>"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Handle Duplicates**"
   ],
   "metadata": {
    "id": "gh5e9Q-Rqr4N"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "df.duplicated().sum()\n",
    "df = df.drop_duplicates()"
   ],
   "metadata": {
    "id": "SMi8TZeNpjIL"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Handle Missing Data**"
   ],
   "metadata": {
    "id": "j9_Dj86zq6ya"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Ensure expected columns exist to avoid KeyErrors downstream\n",
    "for col in ['Company Profile', 'Job Posting Date', 'Country', 'Work Type', 'Job Title', 'Job Description']:\n",
    "    if col not in df.columns:\n",
    "        df[col] = ''\n",
    "\n",
    "df[\"Company Profile\"].fillna(\"Not Provided\", inplace=True)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1FCgHfpCrEKq",
    "outputId": "ab2e6763-d202-4f35-fc88-40a534ef24d5"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/tmp/ipython-input-23678895.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[\"Company Profile\"].fillna(\"Not Provided\", inplace=True)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Data Cleaning**"
   ],
   "metadata": {
    "id": "1sblRA7zrS5b"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "df[\"Job Posting Date\"] = pd.to_datetime(df[\"Job Posting Date\"], errors=\"coerce\")"
   ],
   "metadata": {
    "id": "V2ojepnWrKGq"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Quick Exploratory Data Analysis (EDA)**"
   ],
   "metadata": {
    "id": "Naip7EqKreOL"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "df[\"Country\"].value_counts().head(10)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 429
    },
    "id": "SY_TfjbNrnzT",
    "outputId": "9d2cc4ec-2ac0-4f93-ef54-432ab9433248"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Country\n",
       "Jordan              11\n",
       "Cameroon            10\n",
       "Papua New Guinea    10\n",
       "Maldives             9\n",
       "Solomon Islands      9\n",
       "Brunei               9\n",
       "Kyrgyz Republic      9\n",
       "UK                   9\n",
       "Comoros              9\n",
       "France               9\n",
       "Name: count, dtype: int64"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Jordan</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cameroon</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Papua New Guinea</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maldives</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Solomon Islands</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brunei</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kyrgyz Republic</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UK</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Comoros</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>France</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><br><label><b>dtype:</b> int64</label>"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "df[\"Job Title\"].value_counts().head(10)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 429
    },
    "id": "X6pC-PScsGRc",
    "outputId": "666479c8-65ba-49cf-dff7-7e46dec30fb3"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Job Title\n",
       "UX/UI Designer                 38\n",
       "Software Engineer              23\n",
       "Customer Support Specialist    15\n",
       "Software Tester                14\n",
       "Sales Representative           14\n",
       "Procurement Manager            14\n",
       "Network Administrator          13\n",
       "Litigation Attorney            13\n",
       "Database Administrator         13\n",
       "Supply Chain Manager           13\n",
       "Name: count, dtype: int64"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job Title</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>UX/UI Designer</th>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Software Engineer</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Customer Support Specialist</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Software Tester</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sales Representative</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Procurement Manager</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Network Administrator</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Litigation Attorney</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Database Administrator</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Supply Chain Manager</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><br><label><b>dtype:</b> int64</label>"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "df[\"Work Type\"].value_counts()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "id": "UI63K8iesLGu",
    "outputId": "3f59932f-0d1b-4824-b98f-e555a7388e41"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Work Type\n",
       "Part-Time    213\n",
       "Contract     192\n",
       "Temporary    192\n",
       "Full-Time    188\n",
       "Intern       181\n",
       "Name: count, dtype: int64"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Work Type</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Part-Time</th>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Contract</th>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Temporary</th>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Full-Time</th>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Intern</th>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><br><label><b>dtype:</b> int64</label>"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Check if Salary Range column exists before accessing it\n",
    "if \"Salary Range\" in df.columns:\n",
    "    df[\"Salary Range\"].head(10)\n",
    "else:\n",
    "    print(\"Salary Range column not found in dataset\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 398
    },
    "id": "v1cMfqtIsPow",
    "outputId": "e6c04d18-ff6f-4d40-c041-76bc66c4af91"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0     $59K-$99K\n",
       "1    $56K-$116K\n",
       "2    $61K-$104K\n",
       "3     $65K-$91K\n",
       "4     $64K-$87K\n",
       "5     $59K-$93K\n",
       "6    $63K-$103K\n",
       "7    $65K-$102K\n",
       "8    $65K-$102K\n",
       "9     $60K-$80K\n",
       "Name: Salary Range, dtype: object"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Salary Range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$59K-$99K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$56K-$116K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$61K-$104K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>$65K-$91K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>$64K-$87K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>$59K-$93K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>$63K-$103K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>$65K-$102K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>$65K-$102K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>$60K-$80K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><br><label><b>dtype:</b> object</label>"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## **Save Cleaned Dataset**",
   "metadata": {
    "id": "wXnMZKS_sXmP"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "df.to_csv(\"cleaned_jobs.csv\", index=False)"
   ],
   "metadata": {
    "id": "1Nua6QDXsWMM"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## **Advanced Text Processing & Feature Engineering for JobLens**"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, StackingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# FAST mode for quick runs\n",
    "import os\n",
    "FAST = os.environ.get('JOBLENS_FAST', '0') == '1'\n",
    "print('FAST mode:', FAST)\n",
    "\n",
    "# Optional advanced libs\n",
    "try:\n",
    "    import spacy\n",
    "    from spacy.matcher import PhraseMatcher\n",
    "    _spacy_available = True\n",
    "except Exception:\n",
    "    _spacy_available = False\n",
    "\n",
    "try:\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    _st_available = True\n",
    "except Exception:\n",
    "    _st_available = False\n",
    "\n",
    "try:\n",
    "    import shap\n",
    "    _shap_available = True\n",
    "except Exception:\n",
    "    _shap_available = False\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "\n",
    "print(\"Libraries imported successfully! spaCy:\", _spacy_available, \"SentenceTransformers:\", _st_available, \"SHAP:\", _shap_available)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## **Text Preprocessing Functions**"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"Clean and preprocess text data - unified version\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = str(text).lower()\n",
    "    # Keep alphanumeric characters and spaces for better feature extraction\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "\n",
    "# Improved skill extraction using spaCy PhraseMatcher with fallback to keyword list\n",
    "_skill_list = [\n",
    "    'python','java','javascript','c++','c#','go','rust','sql','html','css','react','angular','vue','node','django','flask','spring',\n",
    "    'kotlin','swift','typescript','pandas','numpy','scikit-learn','pytorch','tensorflow','nlp','bert','transformers','machine learning',\n",
    "    'deep learning','data science','aws','gcp','azure','docker','kubernetes','git','agile','scrum','linux','bash','postgresql','mysql',\n",
    "    'mongodb','redis','grpc','rest','graphql','fastapi','express','next.js','nestjs','ci/cd','terraform','ansible','snowflake','airflow'\n",
    "]\n",
    "\n",
    "if _spacy_available:\n",
    "    try:\n",
    "        try:\n",
    "            nlp = spacy.load('en_core_web_sm')\n",
    "        except Exception:\n",
    "            # Attempt to download model at runtime\n",
    "            from spacy.cli import download as spacy_download\n",
    "            spacy_download('en_core_web_sm')\n",
    "            nlp = spacy.load('en_core_web_sm')\n",
    "        phrase_matcher = PhraseMatcher(nlp.vocab, attr='LOWER')\n",
    "        patterns = [nlp.make_doc(s) for s in _skill_list]\n",
    "        phrase_matcher.add('SKILLS', patterns)\n",
    "    except Exception:\n",
    "        _spacy_available = False\n",
    "        nlp = None\n",
    "        phrase_matcher = None\n",
    "else:\n",
    "    nlp = None\n",
    "    phrase_matcher = None\n",
    "\n",
    "def extract_skills(text: str):\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "    text_s = str(text)\n",
    "    if _spacy_available and nlp is not None and phrase_matcher is not None:\n",
    "        doc = nlp(text_s)\n",
    "        skills = sorted({doc[start:end].text.lower() for _, start, end in phrase_matcher(doc)})\n",
    "        if skills:\n",
    "            return skills\n",
    "    # Fallback: keyword presence\n",
    "    t = text_s.lower()\n",
    "    return sorted({kw for kw in _skill_list if kw in t})\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## **Data Preprocessing for JobLens Model**"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create a clean copy for ML processing\n",
    "df_ml = df.copy()\n",
    "\n",
    "# Apply consistent text cleaning\n",
    "df_ml['Job Title'] = df_ml['Job Title'].astype(str).apply(clean_text)\n",
    "df_ml['Job Description'] = df_ml['Job Description'].astype(str).apply(clean_text)\n",
    "\n",
    "# Combine relevant text fields for job descriptions (guard optional 'Skills')\n",
    "skills_col = 'Skills' if 'Skills' in df_ml.columns else None\n",
    "_df_skills = df_ml[skills_col].fillna('') if skills_col else ''\n",
    "\n",
    "df_ml['combined_job_text'] = (\n",
    "    df_ml['Job Title'].fillna('') + ' ' +\n",
    "    df_ml['Job Description'].fillna('') + ' ' +\n",
    "    (_df_skills if isinstance(_df_skills, pd.Series) else _df_skills) + ' ' +\n",
    "    df_ml['Company Profile'].fillna('')\n",
    ")\n",
    "\n",
    "# Clean the combined text\n",
    "df_ml['cleaned_job_text'] = df_ml['combined_job_text'].apply(clean_text)\n",
    "\n",
    "# Extract skills from job descriptions\n",
    "df_ml['required_skills'] = df_ml['combined_job_text'].apply(extract_skills)\n",
    "df_ml['num_skills_required'] = df_ml['required_skills'].apply(len)\n",
    "\n",
    "# Create synthetic match score for training demo\n",
    "def create_match_score(row):\n",
    "    score = 50\n",
    "    score += min(row['num_skills_required'] * 2, 30)\n",
    "    title = str(row['Job Title']).lower()\n",
    "    if 'senior' in title or 'lead' in title:\n",
    "        score += 15\n",
    "    elif 'junior' in title or 'entry' in title:\n",
    "        score += 10\n",
    "    score += np.random.normal(0, 10)\n",
    "    return max(0, min(100, score))\n",
    "\n",
    "df_ml['match_score'] = df_ml.apply(create_match_score, axis=1)\n",
    "\n",
    "print(f\"Dataset shape after preprocessing: {df_ml.shape}\")\n",
    "print(f\"Match score statistics:\")\n",
    "print(df_ml['match_score'].describe())\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## **Feature Engineering**"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Encode categorical variables with consistent encoders\n",
    "le_country = LabelEncoder()\n",
    "le_work_type = LabelEncoder()\n",
    "\n",
    "# Guard missing columns then encode\n",
    "if 'Country' not in df_ml.columns:\n",
    "    df_ml['Country'] = 'Unknown'\n",
    "if 'Work Type' not in df_ml.columns:\n",
    "    df_ml['Work Type'] = 'Unknown'\n",
    "\n",
    "df_ml['country_encoded'] = le_country.fit_transform(df_ml['Country'].fillna('Unknown'))\n",
    "df_ml['work_type_encoded'] = le_work_type.fit_transform(df_ml['Work Type'].fillna('Unknown'))\n",
    "\n",
    "# Create TF-IDF features from job descriptions\n",
    "# Use fewer features in FAST mode\n",
    "max_feats = 500 if FAST else 1000\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=max_feats,\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=2\n",
    ")\n",
    "\n",
    "tfidf_features = tfidf.fit_transform(df_ml['cleaned_job_text'])\n",
    "tfidf_feature_names = tfidf.get_feature_names_out()\n",
    "print(f\"TF-IDF features shape: {tfidf_features.shape}\")\n",
    "\n",
    "# Optional: Sentence-BERT embeddings (if available)\n",
    "X_bert = None\n",
    "bert_model_name = 'all-MiniLM-L6-v2'\n",
    "if _st_available:\n",
    "    try:\n",
    "        print('Building Sentence-BERT embeddings...')\n",
    "        st_model = SentenceTransformer(bert_model_name)\n",
    "        X_bert = np.vstack(df_ml['cleaned_job_text'].apply(lambda x: st_model.encode(x)).values)\n",
    "        print('Embeddings shape:', X_bert.shape)\n",
    "    except Exception as e:\n",
    "        print('Embedding build skipped due to error:', e)\n",
    "        X_bert = None\n",
    "\n",
    "# Additional numerical features\n",
    "df_ml['job_title_length'] = df_ml['Job Title'].str.len().fillna(0)\n",
    "df_ml['job_desc_length'] = df_ml['Job Description'].str.len().fillna(0)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## **Prepare Training Data**"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Select numerical features for training\n",
    "numerical_features = [\n",
    "    'country_encoded', 'work_type_encoded', 'num_skills_required',\n",
    "    'job_title_length', 'job_desc_length'\n",
    "]\n",
    "\n",
    "X_numerical = df_ml[numerical_features].fillna(0).values\n",
    "X_tfidf = tfidf_features.toarray()\n",
    "\n",
    "# Combine features: numerical + TF-IDF (+ optional BERT)\n",
    "if X_bert is not None:\n",
    "    X = np.hstack([X_numerical, X_tfidf, X_bert])\n",
    "else:\n",
    "    X = np.hstack([X_numerical, X_tfidf])\n",
    "\n",
    "y = df_ml['match_score'].values\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "print(f\"Target variable shape: {y.shape}\")\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## **Model Training - Multiple Algorithms**"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize baseline models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=200, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=200, random_state=42)\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "model_results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name} (baseline)...\")\n",
    "    if name == 'Linear Regression':\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    model_results[name] = {\n",
    "        'model': model,\n",
    "        'mse': mse,\n",
    "        'rmse': rmse,\n",
    "        'mae': mae,\n",
    "        'r2': r2,\n",
    "        'predictions': y_pred\n",
    "    }\n",
    "\n",
    "    print(f\"{name} Results:\")\n",
    "    print(f\"  RMSE: {rmse:.2f}\")\n",
    "    print(f\"  MAE: {mae:.2f}\")\n",
    "    print(f\"  R²: {r2:.3f}\")\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## **Hyperparameter Tuning and Cross-Validation**"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, cross_val_score\n",
    "from scipy.stats import randint as sp_randint, uniform as sp_uniform\n",
    "\n",
    "# Reduce iterations in FAST mode\n",
    "rf_iter = 5 if FAST else 20\n",
    "gb_iter = 5 if FAST else 20\n",
    "\n",
    "# Tune Random Forest\n",
    "rf_param_dist = {\n",
    "    'n_estimators': sp_randint(200, 600),\n",
    "    'max_depth': [None] + list(range(5, 31, 5)),\n",
    "    'min_samples_split': sp_randint(2, 20),\n",
    "    'min_samples_leaf': sp_randint(1, 10),\n",
    "    'max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "rf_search = RandomizedSearchCV(RandomForestRegressor(random_state=42), rf_param_dist, n_iter=rf_iter, cv=3, n_jobs=-1, random_state=42, scoring='r2')\n",
    "print(\"\\nTuning Random Forest...\")\n",
    "rf_search.fit(X_train, y_train)\n",
    "rf_best = rf_search.best_estimator_\n",
    "print(\"RF best params:\", rf_search.best_params_)\n",
    "\n",
    "# Tune Gradient Boosting\n",
    "gb_param_dist = {\n",
    "    'n_estimators': sp_randint(200, 800),\n",
    "    'learning_rate': sp_uniform(0.01, 0.29),\n",
    "    'max_depth': sp_randint(2, 8),\n",
    "    'min_samples_split': sp_randint(2, 20),\n",
    "    'min_samples_leaf': sp_randint(1, 10),\n",
    "    'subsample': sp_uniform(0.6, 0.4)\n",
    "}\n",
    "print(\"Tuning Gradient Boosting...\")\n",
    "gb_search = RandomizedSearchCV(GradientBoostingRegressor(random_state=42), gb_param_dist, n_iter=gb_iter, cv=3, n_jobs=-1, random_state=42, scoring='r2')\n",
    "gb_search.fit(X_train, y_train)\n",
    "gb_best = gb_search.best_estimator_\n",
    "print(\"GB best params:\", gb_search.best_params_)\n",
    "\n",
    "# Evaluate tuned models\n",
    "for name, model in [('Random Forest (tuned)', rf_best), ('Gradient Boosting (tuned)', gb_best)]:\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    model_results[name] = {\n",
    "        'model': model,\n",
    "        'mse': mse,\n",
    "        'rmse': rmse,\n",
    "        'mae': mae,\n",
    "        'r2': r2,\n",
    "        'predictions': y_pred\n",
    "    }\n",
    "    print(f\"{name} -> RMSE: {rmse:.2f}, MAE: {mae:.2f}, R²: {r2:.3f}\")\n",
    "\n",
    "# Cross-validation on best tuned model\n",
    "best_tuned_name = max(['Random Forest (tuned)', 'Gradient Boosting (tuned)'], key=lambda x: model_results[x]['r2'])\n",
    "cv_scores = cross_val_score(model_results[best_tuned_name]['model'], X, y, cv=5, scoring='r2', n_jobs=-1)\n",
    "print(f\"CV R² ({best_tuned_name}) - mean: {cv_scores.mean():.3f}, std: {cv_scores.std():.3f}\")\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## **Stacking Ensemble**"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "stack = StackingRegressor(\n",
    "    estimators=[('rf', rf_best), ('gb', gb_best)],\n",
    "    final_estimator=LinearRegression(),\n",
    "    n_jobs=-1\n",
    ")\n",
    "print(\"Training StackingRegressor...\")\n",
    "stack.fit(X_train, y_train)\n",
    "stack_pred = stack.predict(X_test)\n",
    "stack_mse = mean_squared_error(y_test, stack_pred)\n",
    "stack_rmse = np.sqrt(stack_mse)\n",
    "stack_mae = mean_absolute_error(y_test, stack_pred)\n",
    "stack_r2 = r2_score(y_test, stack_pred)\n",
    "model_results['Stacking'] = {\n",
    "    'model': stack,\n",
    "    'mse': stack_mse,\n",
    "    'rmse': stack_rmse,\n",
    "    'mae': stack_mae,\n",
    "    'r2': stack_r2,\n",
    "    'predictions': stack_pred\n",
    "}\n",
    "print(f\"Stacking -> RMSE: {stack_rmse:.2f}, MAE: {stack_mae:.2f}, R²: {stack_r2:.3f}\")\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## **Model Performance Visualization**"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create performance comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Performance metrics comparison\n",
    "metrics_df = pd.DataFrame({\n",
    "    name: [results['rmse'], results['mae'], results['r2']]\n",
    "    for name, results in model_results.items()\n",
    "}, index=['RMSE', 'MAE', 'R²'])\n",
    "\n",
    "axes[0, 0].bar(metrics_df.columns, metrics_df.loc['RMSE'])\n",
    "axes[0, 0].set_title('RMSE Comparison')\n",
    "axes[0, 0].set_ylabel('RMSE')\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "axes[0, 1].bar(metrics_df.columns, metrics_df.loc['MAE'])\n",
    "axes[0, 1].set_title('MAE Comparison')\n",
    "axes[0, 1].set_ylabel('MAE')\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "axes[1, 0].bar(metrics_df.columns, metrics_df.loc['R²'])\n",
    "axes[1, 0].set_title('R² Score Comparison')\n",
    "axes[1, 0].set_ylabel('R² Score')\n",
    "axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Prediction vs Actual for best model\n",
    "best_model_name = max(model_results.keys(), key=lambda x: model_results[x]['r2'])\n",
    "best_predictions = model_results[best_model_name]['predictions']\n",
    "\n",
    "axes[1, 1].scatter(y_test, best_predictions, alpha=0.6)\n",
    "axes[1, 1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "axes[1, 1].set_xlabel('Actual Match Score')\n",
    "axes[1, 1].set_ylabel('Predicted Match Score')\n",
    "axes[1, 1].set_title(f'Actual vs Predicted ({best_model_name})')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nBest performing model: {best_model_name}\")\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## **Feature Importance Analysis**"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Get the best tree-based model for feature importance\n",
    "best_tree_model = None\n",
    "for name, results in model_results.items():\n",
    "    if name in ['Random Forest', 'Gradient Boosting', 'Random Forest (tuned)', 'Gradient Boosting (tuned)']:\n",
    "        if best_tree_model is None or results['r2'] > model_results[best_tree_model]['r2']:\n",
    "            best_tree_model = name\n",
    "\n",
    "if best_tree_model:\n",
    "    model = model_results[best_tree_model]['model']\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        feature_importance = model.feature_importances_\n",
    "        feature_names = numerical_features + list(tfidf_feature_names) + ( [f'bert_{i}' for i in range(X_bert.shape[1])] if X_bert is not None else [] )\n",
    "        importance_df = pd.DataFrame({\n",
    "            'feature': feature_names,\n",
    "            'importance': feature_importance\n",
    "        }).sort_values('importance', ascending=False).head(20)\n",
    "\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.barh(range(len(importance_df)), importance_df['importance'])\n",
    "        plt.yticks(range(len(importance_df)), importance_df['feature'])\n",
    "        plt.xlabel('Feature Importance')\n",
    "        plt.title(f'Top 20 Feature Importance ({best_tree_model})')\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## **Explainability with SHAP (optional)**"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "if _shap_available and best_tree_model:\n",
    "    try:\n",
    "        explainer = shap.TreeExplainer(model_results[best_tree_model]['model'])\n",
    "        sample_size = 100 if FAST else 200\n",
    "        sample_idx = np.random.choice(len(X_test), size=min(sample_size, len(X_test)), replace=False)\n",
    "        shap_vals = explainer.shap_values(X_test[sample_idx])\n",
    "        shap.summary_plot(shap_vals, features=X_test[sample_idx], feature_names=(numerical_features + list(tfidf_feature_names) + ( [f'bert_{i}' for i in range(X_bert.shape[1])] if X_bert is not None else [] )))\n",
    "    except Exception as e:\n",
    "        print('SHAP explainability skipped:', e)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## **Resume Matching Function**"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def predict_resume_match(job_description, resume_text, model_name=None):\n",
    "    \"\"\"\n",
    "    Predict how well a resume matches a job description using the trained artifacts in this notebook.\n",
    "    Uses TF-IDF + numerical features and appends Sentence-BERT embeddings if available.\n",
    "    \"\"\"\n",
    "    combined_text = clean_text(job_description)\n",
    "    skills = extract_skills(job_description)\n",
    "\n",
    "    features = {\n",
    "        'country_encoded': 0,\n",
    "        'work_type_encoded': 0,\n",
    "        'num_skills_required': len(skills),\n",
    "        'job_title_length': len(job_description),\n",
    "        'job_desc_length': len(job_description)\n",
    "    }\n",
    "\n",
    "    X_num = np.array([[features[col] for col in numerical_features]])\n",
    "    X_text = tfidf.transform([combined_text]).toarray()\n",
    "    X_parts = [X_num, X_text]\n",
    "\n",
    "    # Append embedding if the model was trained with embeddings\n",
    "    if 'X_bert' in globals() and X_bert is not None:\n",
    "        try:\n",
    "            emb = st_model.encode(combined_text).reshape(1, -1)\n",
    "            X_parts.append(emb)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    X_combined = np.hstack(X_parts)\n",
    "\n",
    "    # Choose model\n",
    "    chosen_name = model_name or max(model_results.keys(), key=lambda x: model_results[x]['r2'])\n",
    "    model = model_results[chosen_name]['model']\n",
    "\n",
    "    if isinstance(model, LinearRegression):\n",
    "        X_combined = scaler.transform(X_combined)\n",
    "\n",
    "    match_score = float(model.predict(X_combined)[0])\n",
    "\n",
    "    resume_skills = extract_skills(resume_text)\n",
    "    job_skills = set(skills)\n",
    "    resume_skills_set = set(resume_skills)\n",
    "\n",
    "    skill_overlap = len(job_skills.intersection(resume_skills_set))\n",
    "    missing_skills = list(job_skills - resume_skills_set)\n",
    "\n",
    "    return {\n",
    "        'match_score': max(0.0, min(100.0, match_score)),\n",
    "        'required_skills': skills,\n",
    "        'resume_skills': resume_skills,\n",
    "        'skill_overlap': skill_overlap,\n",
    "        'missing_skills': missing_skills,\n",
    "        'recommendations': f\"Consider adding these skills: {', '.join(missing_skills[:5])}\"\n",
    "    }\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## **Test the Resume Matching Function**"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "sample_job = \"\"\"\n",
    "Senior Python Developer\n",
    "We are looking for an experienced Python developer with expertise in machine learning,\n",
    "web development using Django or Flask, and cloud technologies like AWS.\n",
    "Requirements: 5+ years Python experience, SQL, Docker, Git, Agile methodology.\n",
    "\"\"\"\n",
    "\n",
    "sample_resume = \"\"\"\n",
    "Software Developer with 3 years experience in Python programming.\n",
    "Proficient in web development using Django and Flask frameworks.\n",
    "Experience with SQL databases and version control using Git.\n",
    "Strong problem-solving skills and teamwork abilities.\n",
    "\"\"\"\n",
    "\n",
    "result = predict_resume_match(sample_job, sample_resume)\n",
    "\n",
    "print(\"JobLens Resume Matching Results:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Match Score: {result['match_score']:.1f}/100\")\n",
    "print(f\"Skills Overlap: {result['skill_overlap']}/{len(result['required_skills'])}\")\n",
    "print(f\"Required Skills: {', '.join(result['required_skills'])}\")\n",
    "print(f\"Resume Skills: {', '.join(result['resume_skills'])}\")\n",
    "print(f\"Missing Skills: {', '.join(result['missing_skills'])}\")\n",
    "print(f\"Recommendations: {result['recommendations']}\")\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## **Save the Trained Model and Components**"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import joblib\n",
    "\n",
    "best_model_name = max(model_results.keys(), key=lambda x: model_results[x]['r2'])\n",
    "best_model = model_results[best_model_name]['model']\n",
    "\n",
    "model_package = {\n",
    "    'model': best_model,\n",
    "    'tfidf_vectorizer': tfidf,\n",
    "    'scaler': scaler,\n",
    "    'label_encoders': {\n",
    "        'country': le_country,\n",
    "        'work_type': le_work_type\n",
    "    },\n",
    "    'feature_names': numerical_features,\n",
    "    'use_embeddings': X_bert is not None,\n",
    "    'embedding_model': ('sentence-transformers', bert_model_name) if X_bert is not None else None,\n",
    "    'model_name': best_model_name,\n",
    "    'model_performance': {k: v for k, v in model_results[best_model_name].items() if k != 'model'}\n",
    "}\n",
    "\n",
    "joblib.dump(model_package, 'joblens_model.pkl')\n",
    "\n",
    "print(\"Model saved successfully!\")\n",
    "print(f\"Best model: {best_model_name}\")\n",
    "print(f\"Model performance: R² = {model_results[best_model_name]['r2']:.3f}\")\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## **Model Usage Instructions for Backend Integration**"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"\"\"\n",
    "JobLens Model Integration Guide:\n",
    "================================\n",
    "\n",
    "1. Load the model in your Rust backend:\n",
    "   - Use the saved 'joblens_model.pkl' file\n",
    "   - The model package contains all preprocessing components\n",
    "\n",
    "2. Model Input Requirements:\n",
    "   - Job description text\n",
    "   - Resume text (optional for job-only analysis)\n",
    "\n",
    "3. Model Output:\n",
    "   - Match score (0-100)\n",
    "   - Required skills list\n",
    "   - Missing skills recommendations\n",
    "   - Skill overlap metrics\n",
    "\n",
    "4. API Endpoint Design:\n",
    "   POST /api/analyze-match\n",
    "   {\n",
    "     \"job_description\": \"string\",\n",
    "     \"resume_text\": \"string\"\n",
    "   }\n",
    "\n",
    "   Response:\n",
    "   {\n",
    "     \"match_score\": float,\n",
    "     \"required_skills\": [string],\n",
    "     \"missing_skills\": [string],\n",
    "     \"recommendations\": string\n",
    "   }\n",
    "\n",
    "5. For Rust Integration:\n",
    "   - Use onnxruntime for tree models exported to ONNX (optional)\n",
    "   - Or invoke Python for inference via a subprocess/microservice\n",
    "   - Implement text preprocessing in Rust to mirror this pipeline\n",
    "\n",
    "Next Steps:\n",
    "- If using embeddings at inference, load SentenceTransformer('all-MiniLM-L6-v2') in your service\n",
    "- Create API endpoints in your Rust backend\n",
    "- Test with real resume and job description data\n",
    "\"\"\")\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## **Export Model to ONNX (Optional for Rust Integration)**"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "try:\n",
    "    from skl2onnx import convert_sklearn\n",
    "    from skl2onnx.common.data_types import FloatTensorType\n",
    "\n",
    "    initial_type = [('float_input', FloatTensorType([None, X_train.shape[1]]))]\n",
    "\n",
    "    # Only export tree-based or linear models that skl2onnx supports well\n",
    "    if any(key in best_model_name for key in ['Random Forest', 'Gradient Boosting']):\n",
    "        onnx_model = convert_sklearn(best_model, initial_types=initial_type)\n",
    "        with open(\"joblens_model.onnx\", \"wb\") as f:\n",
    "            f.write(onnx_model.SerializeToString())\n",
    "        print(\"ONNX model saved successfully!\")\n",
    "        print(\"Use this for Rust backend integration with onnxruntime-rs\")\n",
    "    else:\n",
    "        print(\"Model not exported to ONNX. Use the pickle file instead.\")\n",
    "\n",
    "except ImportError:\n",
    "    print(\"skl2onnx not installed. Install with: pip install skl2onnx\")\n",
    "    print(\"For now, use the pickle file for model deployment\")\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## **Final Model Summary**"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"JobLens AI Model Training Complete!\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Dataset size: {df_ml.shape[0]} job postings\")\n",
    "print(f\"Feature count: {X.shape[1]} features\")\n",
    "print(f\"Best model: {best_model_name}\")\n",
    "print(f\"Model accuracy (R²): {model_results[best_model_name]['r2']:.3f}\")\n",
    "print(f\"RMSE: {model_results[best_model_name]['rmse']:.2f}\")\n",
    "\n",
    "print(\"\\nModel Capabilities:\")\n",
    "print(\"- Resume-job matching with 0-100 score\")\n",
    "print(\"- Skill gap analysis\")\n",
    "print(\"- Missing skill recommendations\")\n",
    "print(\"- Feature importance analysis\")\n",
    "print(\"- Optional Sentence-BERT embeddings (if available)\")\n",
    "\n",
    "print(\"\\nFiles Generated:\")\n",
    "print(\"- joblens_model.pkl (Complete model package)\")\n",
    "print(\"- joblens_model.onnx (For Rust integration, if available)\")\n",
    "print(\"- cleaned_jobs.csv (Processed dataset)\")\n",
    "\n",
    "print(\"\\nReady for integration with JobLens backend!\")\n"
   ]
  }
 ]
}
